# <div align="center"> <strong>Multi-Head Attention-Based Framework with Residual Network for Human Action Recognition</strong> </div>

![Model Architecture](./images/model.png)

---

##  Overview

This repository provides the full implementation of our human action recognition framework described in the paper:

**"Multi-Head Attention-Based Framework with Residual Network for Human Action Recognition"**  
 *Sensors, 2025*  
ğŸ”— [DOI: 10.3390/s25092930](https://www.mdpi.com/1424-8220/25/9/2930)

Our framework combines:
- âœ… **ResNet-18** for extracting spatial features
- ğŸ” **BiLSTM** for modeling temporal dynamics
- ğŸ¯ **Multi-Head Attention** for motion focus
- ğŸŒ€ **Motion-based Frame Selection** via optical flow

---

## ğŸ“‚ Project Structure

```bash
HAR-ResNet-BiLSTM-Attention/
â”œâ”€â”€ configs/                  # Configuration files
â”œâ”€â”€ extracted_features/      # Extracted Features from row dataset
â”œâ”€â”€ checkpoints/             # Saved model checkpoints
â”œâ”€â”€ logs/                    # Training/validation logs and plots
â”œâ”€â”€ images/                  # Visuals (model diagram, etc.)
â”‚   â””â”€â”€ model.png
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ extract_feature_nm.py    # Feature extraction (no motion consideration)
â”‚   â”œâ”€â”€ extract_feature_wm.py    # Feature extraction (with motion consideration)
â”‚   â”œâ”€â”€ lstm_model.py            # BiLSTM + Attention model definition
â”‚   â”œâ”€â”€ test_on_pc_camera.py     # Test model with webcam input
â”‚   â”œâ”€â”€ test_on_ucf101_data.py   # Evaluate model on full UCF101 test set
â”‚   â””â”€â”€ training_model_bilstm.py # Train model with extracted features
